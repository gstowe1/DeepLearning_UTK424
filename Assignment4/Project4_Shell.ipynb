{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2adb05c1",
   "metadata": {},
   "source": [
    "# Project 4\n",
    "## Students:\n",
    " > [Eli Carter]\n",
    " > [Gabriel Stowe]\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "563a5a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 13:56:40.213071: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2ebf08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)# you may want to upgrade to 2.10.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a95a42",
   "metadata": {},
   "source": [
    "### Please Use Markdown\n",
    "> for markdown, see here: https://www.ibm.com/docs/en/watson-studio-local/1.2.3?topic=notebooks-markdown-jupyter-cheatsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddae40d9",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2493f996",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel():\n",
    "    def __init__(self, vocab_size, embed_dim=256, num_heads=2, num_blocks=1, ff_dim=256, maxlen=64, rate=0.1):\n",
    "        #initailize variables\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.num_blocks = num_blocks\n",
    "        self.ff_dim = ff_dim\n",
    "        self.maxlen = maxlen\n",
    "        self.rate = rate\n",
    "\n",
    "    def TransformerBlock(self, inputs):\n",
    "        #create the transformer block as discribed in the writeup, use the Keras functional API (https://keras.io/guides/functional_api/)\n",
    "        #MultiHeadAttention layer, specifiy 'use_causal_mask=True' (https://keras.io/api/layers/attention_layers/multi_head_attention/)\n",
    "        #LayerNormalization layer, specifiy 'epsilon=1e-6' (https://keras.io/api/layers/normalization_layers/layer_normalization/)\n",
    "        #Use the rate variable for the dropout layers\n",
    "        mha = tf.keras.layers.MultiHeadAttention(num_heads=self.num_heads, key_dim=self.embed_dim)(inputs, inputs, use_causal_mask=True)\n",
    "        d1 = layers.Dropout(self.rate)(mha)\n",
    "        n1 = layers.LayerNormalization(epsilon=1e-6)(d1 + inputs)\n",
    "        fc1 = layers.Dense(self.ff_dim, activation='relu')(n1)\n",
    "        fc2 = layers.Dense(self.ff_dim, activation='relu')(fc1)\n",
    "        d2 = layers.Dropout(self.rate)(fc2)\n",
    "        n2 = layers.LayerNormalization(epsilon=1e-6)(d2 + n1)\n",
    "        return n2\n",
    "\n",
    "\n",
    "    \n",
    "    def EmbeddingLayer(self, inputs):\n",
    "        #create the embedding layer\n",
    "        #create (1) an embedding for the tokens and (2) an embedding for the positions\n",
    "        #you can use https://keras.io/api/layers/core_layers/embedding/ Embedding class\n",
    "        #you can use tf.range to enocde positions\n",
    "        #add (1) and (2) and return the layer\n",
    "        toke_embedding = layers.Embedding(input_dim=self.vocab_size, output_dim=self.embed_dim)(inputs)\n",
    "        pos_embedding = layers.Embedding(input_dim=self.maxlen, output_dim=self.embed_dim)(tf.range(self.maxlen))\n",
    "        return toke_embedding + pos_embedding\n",
    "        #return layers.TokenAndPositionEmbedding(self.maxlen, self.vocab_size, self.embed_dim)(inputs)\n",
    "    \n",
    "    def create_model(self):\n",
    "        #combine the EmbeddingLayer and num_blocks TransformerBlocks to create the model, use the Keras functional API (https://keras.io/guides/functional_api/)\n",
    "        #use the SparseCategoricalCrossentropy loss function (https://keras.io/api/losses/probabilistic_losses/#sparsecategoricalcrossentropy-class)\n",
    "\n",
    "        inputs = layers.Input(shape=(self.maxlen,))\n",
    "        embedding = self.EmbeddingLayer(inputs)\n",
    "        tmp = embedding\n",
    "        for i in range(self.num_blocks):\n",
    "            tmp = self.TransformerBlock(tmp)\n",
    "\n",
    "        outputs = layers.Dense(self.vocab_size, activation='softmax')(tmp)\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        print(model.summary())\n",
    "        keras.utils.plot_model(model, \"model.png\", show_shapes=True)\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ad747b",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "227111a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet():\n",
    "    def __init__(self, filename, len):\n",
    "        #load the text from the file\n",
    "        self.text = open(filename, 'r').read()\n",
    "        self.len = len\n",
    "        \n",
    "\n",
    "    def prep_text(self):\n",
    "        #remove all punctuation\n",
    "        self.text = re.sub(r'[^\\w\\s]', '', self.text)\n",
    "        #remove all special characters\n",
    "        self.text = re.sub(r'[^a-zA-Z0-9\\s]', '', self.text)\n",
    "        #replace all whitespaces except for \\n with a space\n",
    "        self.text = re.sub(r'[^\\S\\n]+', ' ', self.text)\n",
    "        #replace all \\n with a space, newline, then space\n",
    "        self.text = re.sub(r'\\n', ' \\n ', self.text)\n",
    "        \n",
    "    def tokenize_text(self):\n",
    "        #seperate into words, create a vocab and convert the text to a list of numbers using the vocab such that each unique word is represented by its own number\n",
    "        self.text = self.text.split(' ')\n",
    "        #remove all the empty strings ??????\n",
    "        c = self.text.count('')\n",
    "        for i in range(c):\n",
    "            self.text.remove('')\n",
    "        self.vocab = np.unique(self.text)\n",
    "        self.text = np.array([np.where(self.vocab == word)[0][0] for word in self.text])\n",
    "\n",
    "    def create_dataset(self):\n",
    "        #split the tokenized data into sequences of length len, return the sequences and vocab\n",
    "        self.prep_text()\n",
    "        self.tokenize_text()\n",
    "        x = []\n",
    "        y = []\n",
    "        for i in range(len(self.text) - self.len - 1):\n",
    "            x.append(self.text[i:i+self.len])\n",
    "            y.append(self.text[i+1:i+self.len+1])\n",
    "        return np.array(x), np.array(y), self.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3cce1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  13  511 1072 2226 1232    0 1053 1756 2226 1499 2280 1552  261    0\n",
      "   18   13 1300 1330 2487 1310 2226  897    0   64 2252 2226 1499 2435\n",
      " 1754 1848    0 2467 1053 1136  925 2279 1197    0 1053 1869 2226 1640\n",
      "    0  959  229 1007 1397 1582 1072   13  320    0  959  548 1530 2224\n",
      " 2226 1239  925  356    0   13  466 1549]\n",
      "[ 511 1072 2226 1232    0 1053 1756 2226 1499 2280 1552  261    0   18\n",
      "   13 1300 1330 2487 1310 2226  897    0   64 2252 2226 1499 2435 1754\n",
      " 1848    0 2467 1053 1136  925 2279 1197    0 1053 1869 2226 1640    0\n",
      "  959  229 1007 1397 1582 1072   13  320    0  959  548 1530 2224 2226\n",
      " 1239  925  356    0   13  466 1549 1628]\n",
      "['\\n' '0' '1' ... 'zapped' 'zoo' 'zu']\n",
      "2595\n"
     ]
    }
   ],
   "source": [
    "test = DataSet('beatles.txt', 64)\n",
    "x, y, vocab = test.create_dataset()\n",
    "print(x[0])\n",
    "print(y[0])\n",
    "print(vocab)\n",
    "print(len(vocab))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c3a399",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ffe1274",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateText():\n",
    "    def __init__(self, model, vocab):\n",
    "        self.vocab = vocab\n",
    "        self.model = model\n",
    "\n",
    "    \n",
    "    def generate_text(self, start_string, num_generate=100):\n",
    "        #generate text using the model and vocab, start with the start_string and generate num_generate words\n",
    "        #use the model to predict the next word, then add it to the input and predict the next word, repeat until num_generate words have been generated\n",
    "\n",
    "        #convert the start_string to a list of numbers using the vocab\n",
    "        start_tokens = [np.where(self.vocab == word)[0][0] for word in start_string.split(' ')]\n",
    "        \n",
    "        for i in range(num_generate):\n",
    "            #use the model to predict the next word\n",
    "            prediction = self.model.predict(start_tokens)\n",
    "            #add the predicted word to the input\n",
    "            start_tokens.append(np.argmax(prediction))\n",
    "        #convert the list of numbers back to a string using the vocab\n",
    "        return ' '.join([self.vocab[i] for i in start_tokens])\n",
    "    \n",
    "    def generate_random_text(self, num_generate=100):\n",
    "        #generate text using the model and vocab, start with a random word and generate num_generate words\n",
    "\n",
    "        #choose a random word from the vocab as the start_string\n",
    "        start_string = np.random.choice(self.vocab)\n",
    "        return self.generate_text(start_string, num_generate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0bd9d",
   "metadata": {},
   "source": [
    "## Task 4: Model Traning and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b59dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model while periodically generating text to show progress\n",
    "def train_model(model, vocab, x, y, epochs=50, verbose=1):\n",
    "    gen_text = GenerateText(model, vocab)\n",
    "    for i in range(epochs):\n",
    "        #train the model\n",
    "        model = model.fit(x, y)\n",
    "        \n",
    "        if i % 10 == 0 and verbose == 1:\n",
    "            #generate text using the model\n",
    "            print(f'Epoch {i}')\n",
    "            print(gen_text.generate_random_text())\n",
    "            print('\\n\\n')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f390b808",
   "metadata": {},
   "source": [
    "## Running the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17d89c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int64'>\n",
      "(38847, 64)\n",
      "(38847, 64)\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, 64, 256)      664320      ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TFOpLa  (None, 64, 256)     0           ['embedding_6[0][0]']            \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 64, 256)     526080      ['tf.__operators__.add_9[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_9[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 64, 256)      0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (TFOpL  (None, 64, 256)     0           ['dropout_6[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_9[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 64, 256)     512         ['tf.__operators__.add_10[0][0]']\n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 64, 256)      65792       ['layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 64, 256)      65792       ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 64, 256)      0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (TFOpL  (None, 64, 256)     0           ['dropout_7[0][0]',              \n",
      " ambda)                                                           'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 64, 256)     512         ['tf.__operators__.add_11[0][0]']\n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 64, 2595)     666915      ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,989,923\n",
      "Trainable params: 1,989,923\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "1214/1214 [==============================] - 272s 222ms/step - loss: 1.8664 - accuracy: 0.5774\n",
      "Epoch 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.int64'>\"}), <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m compiled_model \u001b[39m=\u001b[39m my_model\u001b[39m.\u001b[39mcreate_model()\n\u001b[1;32m     12\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m trained_model \u001b[39m=\u001b[39m train_model(compiled_model, vocab, x, y)\n",
      "Cell \u001b[0;32mIn[14], line 11\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, vocab, x, y, epochs, verbose)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m verbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m      9\u001b[0m         \u001b[39m#generate text using the model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m         \u001b[39mprint\u001b[39m(gen_text\u001b[39m.\u001b[39;49mgenerate_random_text())\n\u001b[1;32m     12\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "Cell \u001b[0;32mIn[13], line 27\u001b[0m, in \u001b[0;36mGenerateText.generate_random_text\u001b[0;34m(self, num_generate)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_random_text\u001b[39m(\u001b[39mself\u001b[39m, num_generate\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m):\n\u001b[1;32m     23\u001b[0m     \u001b[39m#generate text using the model and vocab, start with a random word and generate num_generate words\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m     \u001b[39m#choose a random word from the vocab as the start_string\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     start_string \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab)\n\u001b[0;32m---> 27\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_text(start_string, num_generate)\n",
      "Cell \u001b[0;32mIn[13], line 16\u001b[0m, in \u001b[0;36mGenerateText.generate_text\u001b[0;34m(self, start_string, num_generate)\u001b[0m\n\u001b[1;32m     12\u001b[0m start_tokens \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mwhere(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab \u001b[39m==\u001b[39m word)[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m start_string\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_generate):\n\u001b[1;32m     15\u001b[0m     \u001b[39m#use the model to predict the next word\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     prediction \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(start_tokens)\n\u001b[1;32m     17\u001b[0m     \u001b[39m#add the predicted word to the input\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     start_tokens\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39margmax(prediction))\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/py38/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/py38/lib/python3.8/site-packages/keras/engine/data_adapter.py:1082\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1079\u001b[0m adapter_cls \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m ALL_ADAPTER_CLS \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcan_handle(x, y)]\n\u001b[1;32m   1080\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m adapter_cls:\n\u001b[1;32m   1081\u001b[0m     \u001b[39m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m-> 1082\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1083\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to find data adapter that can handle input: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1084\u001b[0m             _type_name(x), _type_name(y)\n\u001b[1;32m   1085\u001b[0m         )\n\u001b[1;32m   1086\u001b[0m     )\n\u001b[1;32m   1087\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(adapter_cls) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1088\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1089\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mData adapters should be mutually exclusive for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1090\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhandling inputs. Found multiple adapters \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1091\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[1;32m   1092\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.int64'>\"}), <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "dataset = DataSet('beatles.txt', 64)\n",
    "x, y, vocab = dataset.create_dataset()\n",
    "print(type(x))\n",
    "print(type(x[0]))\n",
    "print(type(x[0][0]))\n",
    "print(type(y))\n",
    "print(type(y[0]))\n",
    "print(type(y[0][0]))\n",
    "print(np.shape(x))\n",
    "print(np.shape(y))\n",
    "# Create the model\n",
    "my_model = TransformerModel(len(vocab))\n",
    "compiled_model = my_model.create_model()\n",
    "# Train the model\n",
    "trained_model = train_model(compiled_model, vocab, x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658fa81b",
   "metadata": {},
   "source": [
    "\n",
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b723a2",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855b442",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c41dc86",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3812e555",
   "metadata": {},
   "source": [
    "## How to Run Code\n",
    "\n",
    "Please include any special libraries and list your tf version here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
